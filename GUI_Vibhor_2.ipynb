{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting whoosh\n",
      "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468kB)\n",
      "\u001b[K    100% |████████████████████████████████| 471kB 847kB/s \n",
      "\u001b[?25hInstalling collected packages: whoosh\n",
      "Successfully installed whoosh-2.7.4\n",
      "\u001b[33mYou are using pip version 8.1.2, however version 9.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install whoosh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#function wont work if import statement is inside, must be outside\n",
    "from whoosh.analysis import Filter\n",
    "class CustomFilter(Filter):\n",
    "    # This filter will run for both the index and the query\n",
    "    is_morph = True\n",
    "    def __init__(self, filterFunc, *args, **kwargs):\n",
    "        self.customFilter = filterFunc\n",
    "        self.args = args\n",
    "        self.kwargs = kwargs\n",
    "    def __eq__(self):\n",
    "        return (other\n",
    "                and self.__class__ is other.__class__)\n",
    "    def __call__(self, tokens):\n",
    "        for t in tokens:\n",
    "            if t.mode == 'query': # if called by query parser\n",
    "                t.text = self.customFilter(t.text, *self.args, **self.kwargs)\n",
    "                yield t\n",
    "            else: # == 'index' if called by indexer\n",
    "                t.text = self.customFilter(t.text, *self.args, **self.kwargs)\n",
    "                yield t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shopifySearch(df, userQuery):\n",
    "    #!pip --quiet install whoosh\n",
    "    from whoosh import index, writing\n",
    "    from whoosh.fields import Schema, TEXT, ID, STORED\n",
    "    from whoosh.analysis import RegexTokenizer, LowercaseFilter, StopFilter, StemFilter\n",
    "    from whoosh import qparser\n",
    "    from whoosh.qparser import QueryParser, GtLtPlugin, PhrasePlugin, SequencePlugin\n",
    "    from whoosh import scoring\n",
    "    import os, os.path # os - portable way of using operating system dependent functionality\n",
    "    import shutil #High-level file operations\n",
    "    import pandas\n",
    "    import nltk\n",
    "    \n",
    "    \n",
    "    #Defining constants for the data paths ***** MODIFY ACCORDINGLY *****\n",
    "    INDEX_DIR = r\"\\Desktop\"\n",
    "    \n",
    "    \n",
    "    #BUILD SCHEMA ****\n",
    "    #schema has fields - piece of info for each doc in the index\n",
    "    customWordFilter = RegexTokenizer()|LowercaseFilter()|CustomFilter(nltk.stem.porter.PorterStemmer().stem)|CustomFilter(nltk.WordNetLemmatizer().lemmatize)\n",
    "\n",
    "    ixSchema = Schema(comment_ID = ID(stored=True),\n",
    "                         comment_Subreddit = ID(stored=True),\n",
    "                         #note analyzer is a wrapper for a tokenizer and zero or more filters -- i.e. allows you to combine them\n",
    "                         comment_Content = TEXT(analyzer = customWordFilter))\n",
    "  \n",
    "\n",
    "    #BUILD INDEX ****\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(INDEX_DIR):\n",
    "        os.mkdir(INDEX_DIR)\n",
    "\n",
    "\n",
    "#     if index exists - remove it\n",
    "#     #Return True if path is an existing directory.\n",
    "#     if os.path.isdir(INDEX_DIR):\n",
    "#         #Delete an entire directory tree; path must point to a directory\n",
    "#         shutil.rmtree(INDEX_DIR)\n",
    "#     #create the directory for the index\n",
    "#     os.makedirs(INDEX_DIR)\n",
    "\n",
    "    #initiate index - takes two inputs, the index directory and the schema for the index\n",
    "    ix = index.create_in(INDEX_DIR,ixSchema)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #INDEX COMMENTS ****\n",
    "    #creating a utility writer \n",
    "    #params: index – the whoosh.index.Index to write to.\n",
    "    #period – the maximum amount of time (in seconds) between commits.\n",
    "    #limit – the maximum number of documents to buffer before committing/between commits.\n",
    "    writer = writing.BufferedWriter(ix, period=20, limit=1000)\n",
    "    try:\n",
    "        # write each file to index\n",
    "        # enumerate returns index,value index points too --> index,a[index]\n",
    "        \n",
    "        counter1 = 0\n",
    "        for row in df.iterrows():\n",
    "            index,data = row\n",
    "            writer.add_document(comment_ID = data['name'],\n",
    "                                comment_Subreddit = data['subreddit'],\n",
    "                                comment_Content = data['body'])\n",
    "            counter1 = counter1 + 1\n",
    "            \n",
    "#             if (counter1 % 100 == 0):\n",
    "#                 print(\"already indexed:\", counter1+1)\n",
    "\n",
    "    finally:\n",
    "        # save the index\n",
    "        #print(\"done indexing\")\n",
    "        # *** Note *** -> Must explictly call close() on the writer object to release the write lock and makesure uncommited changes are saved \n",
    "        writer.close()   \n",
    "      \n",
    "    \n",
    "    #PARSE USER QUERY ****\n",
    "    \n",
    "    #in the query parser --> we pass the DEFAULT field to search and the schema of the index we are searching\n",
    "    #NOTE: Users can still specify a search on a different field in the schema via --> <fieldname>: <query>\n",
    "    qp = QueryParser(\"comment_Content\", schema=ix.schema)\n",
    "\n",
    "     #Once you have a QueryParser object, you can call parse() on it to parse a query string into a query object:\n",
    "        #default query lang: \n",
    "        #If the user doesn’t explicitly specify AND or OR clauses: \n",
    "        #by default, the parser treats the words as if they were connected by AND,\n",
    "        #meaning all the terms must be present for a document to match\n",
    "        #we will change this \n",
    "        #to phrase search \"<query>\" - use quotes\n",
    "        \n",
    "    qp.add_plugin(qparser.GtLtPlugin)   \n",
    "    #qp.remove_plugin_class(qparser.PhrasePlugin)\n",
    "    qp.add_plugin(qparser.PhrasePlugin)  \n",
    "    query = qp.parse(userQuery)\n",
    "    print(\"\\n\\n Query: \")\n",
    "    print(query)\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    ##IMPLEMENT SEARCHER ****\n",
    "    resultsDF = pandas.DataFrame() #creates a new dataframe that's empty to store the results comment content\n",
    "    with ix.searcher(weighting = scoring.BM25F()) as searcher:\n",
    "        queryResults = searcher.search(query, limit = None)\n",
    "        print(\"Total Number of Results:\",len(queryResults))\n",
    "        print(\"Number of scored and sorted docs in this Results object:\",queryResults.scored_length())\n",
    "        for result in queryResults:\n",
    "#             print(result)\n",
    "#             print(\"\\n\",result['comment_ID'])\n",
    "            resultsDF = resultsDF.append(df.loc[df['name']== result['comment_ID']][['name','subreddit','body']])\n",
    "            \n",
    "\n",
    "    #print(dataDf.loc[dataDf['body']==comment].index.values[0])\n",
    "        \n",
    "    return resultsDF     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ShopifySearchEngine(df, userQuery):\n",
    "    #!pip --quiet install whoosh\n",
    "    from whoosh import index, writing\n",
    "    from whoosh.fields import Schema, TEXT, ID, STORED\n",
    "    from whoosh.analysis import RegexTokenizer, LowercaseFilter, StopFilter, StemFilter\n",
    "    from whoosh import qparser\n",
    "    from whoosh.qparser import QueryParser, GtLtPlugin, PhrasePlugin, SequencePlugin\n",
    "    from whoosh import scoring\n",
    "    import os, os.path # os - portable way of using operating system dependent functionality\n",
    "    import shutil #High-level file operations\n",
    "    import pandas\n",
    "    import nltk\n",
    "    \n",
    "    \n",
    "    #Defining constants for the data paths ***** MODIFY ACCORDINGLY *****\n",
    "    INDEX_DIR = r\"C:\\Users\\Jason\\MIE490 - Capstone - Shopify\\Data\\Index2\"\n",
    "    \n",
    "    \n",
    "    #BUILD SCHEMA ****\n",
    "    #schema has fields - piece of info for each doc in the index\n",
    "    customWordFilter = RegexTokenizer()|LowercaseFilter()|CustomFilter(nltk.stem.porter.PorterStemmer().stem)|CustomFilter(nltk.WordNetLemmatizer().lemmatize)\n",
    "\n",
    "    ixSchema = Schema(comment_ID = ID(stored=True),\n",
    "                         comment_Subreddit = ID(stored=True),\n",
    "                         #note analyzer is a wrapper for a tokenizer and zero or more filters -- i.e. allows you to combine them\n",
    "                         comment_Content = TEXT(analyzer = customWordFilter))\n",
    "  \n",
    "\n",
    "    #BUILD INDEX ****\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(INDEX_DIR):\n",
    "        os.mkdir(INDEX_DIR)\n",
    "\n",
    "\n",
    "#     if index exists - remove it\n",
    "#     #Return True if path is an existing directory.\n",
    "#     if os.path.isdir(INDEX_DIR):\n",
    "#         #Delete an entire directory tree; path must point to a directory\n",
    "#         shutil.rmtree(INDEX_DIR)\n",
    "#     #create the directory for the index\n",
    "#     os.makedirs(INDEX_DIR)\n",
    "\n",
    "    #initiate index - takes two inputs, the index directory and the schema for the index\n",
    "    ix = index.create_in(INDEX_DIR,ixSchema)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #INDEX COMMENTS ****\n",
    "    #creating a utility writer \n",
    "    #params: index – the whoosh.index.Index to write to.\n",
    "    #period – the maximum amount of time (in seconds) between commits.\n",
    "    #limit – the maximum number of documents to buffer before committing/between commits.\n",
    "    writer = writing.BufferedWriter(ix, period=20, limit=1000)\n",
    "    try:\n",
    "        # write each file to index\n",
    "        # enumerate returns index,value index points too --> index,a[index]\n",
    "        \n",
    "        counter1 = 0\n",
    "        for row in df.iterrows():\n",
    "            index,data = row\n",
    "            writer.add_document(comment_ID = data['name'],\n",
    "                                comment_Subreddit = data['subreddit'],\n",
    "                                comment_Content = data['body'])\n",
    "            counter1 = counter1 + 1\n",
    "            \n",
    "#             if (counter1 % 100 == 0):\n",
    "#                 print(\"already indexed:\", counter1+1)\n",
    "\n",
    "    finally:\n",
    "        # save the index\n",
    "        #print(\"done indexing\")\n",
    "        # *** Note *** -> Must explictly call close() on the writer object to release the write lock and makesure uncommited changes are saved \n",
    "        writer.close()   \n",
    "      \n",
    "    \n",
    "    #PARSE USER QUERY ****\n",
    "    \n",
    "    #in the query parser --> we pass the DEFAULT field to search and the schema of the index we are searching\n",
    "    #NOTE: Users can still specify a search on a different field in the schema via --> <fieldname>: <query>\n",
    "    qp = QueryParser(\"comment_Content\", schema=ix.schema)\n",
    "\n",
    "     #Once you have a QueryParser object, you can call parse() on it to parse a query string into a query object:\n",
    "        #default query lang: \n",
    "        #If the user doesn’t explicitly specify AND or OR clauses: \n",
    "        #by default, the parser treats the words as if they were connected by AND,\n",
    "        #meaning all the terms must be present for a document to match\n",
    "        #we will change this \n",
    "        #to phrase search \"<query>\" - use quotes\n",
    "        \n",
    "    qp.add_plugin(qparser.GtLtPlugin)   \n",
    "    #qp.remove_plugin_class(qparser.PhrasePlugin)\n",
    "    qp.add_plugin(qparser.PhrasePlugin)  \n",
    "    query = qp.parse(userQuery)\n",
    "    print(\"\\n\\n Query: \")\n",
    "    print(query)\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    ##IMPLEMENT SEARCHER ****\n",
    "    resultsDF = pandas.DataFrame() #creates a new dataframe that's empty to store the results comment content\n",
    "    with ix.searcher(weighting = scoring.BM25F()) as searcher:\n",
    "        queryResults = searcher.search(query, limit = None)\n",
    "        print(\"Total Number of Results:\",len(queryResults))\n",
    "        print(\"Number of scored and sorted docs in this Results object:\",queryResults.scored_length())\n",
    "        for result in queryResults:\n",
    "#             print(result)\n",
    "#             print(\"\\n\",result['comment_ID'])\n",
    "            resultsDF = resultsDF.append(df.loc[df['name']== result['comment_ID']][['name','subreddit','body']])\n",
    "            \n",
    "\n",
    "    #print(dataDf.loc[dataDf['body']==comment].index.values[0])\n",
    "        \n",
    "    return resultsDF     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>MI</th>\n",
       "      <th>PMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Awesome room service</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good view</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ok view</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bad room service</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Terrible prices</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Disastrous prices</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   text   MI   PMI\n",
       "0  Awesome room service    1  0.75\n",
       "1             Good view  0.5  0.75\n",
       "2               Ok view    0   0.5\n",
       "3      Bad room service -0.5     0\n",
       "4       Terrible prices   -1 -0.75\n",
       "5     Disastrous prices   -1    -1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pandas.DataFrame(columns=['text','MI', 'PMI'],index=[0,1,2,3])\n",
    "df.loc[0] = pandas.Series({'text':\"Awesome room service\", 'MI':1, 'PMI':0.75})\n",
    "df.loc[1] = pandas.Series({'text':\"Good view\", 'MI':0.5, 'PMI':0.75})\n",
    "df.loc[2] = pandas.Series({'text':\"Ok view\", 'MI':0, 'PMI':0.5})\n",
    "df.loc[3] = pandas.Series({'text':\"Bad room service\", 'MI':-0.5, 'PMI':0})\n",
    "df.loc[4] = pandas.Series({'text':\"Terrible prices\", 'MI':-1, 'PMI':-0.75})\n",
    "df.loc[5] = pandas.Series({'text':\"Disastrous prices\", 'MI':-1, 'PMI':-1})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###import stuff\n",
    "import tkinter\n",
    "from tkinter import *\n",
    "import tkinter.font as tkFont\n",
    "import tkinter.ttk as ttk\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import sqlite3\n",
    "from tkinter.ttk import Combobox,Treeview,Scrollbar\n",
    "\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Create Table\n",
    "class TableApp(Frame):\n",
    "\n",
    "    def __init__(self, parent):\n",
    "        Frame.__init__(self, parent)\n",
    "        self.CreateTable()\n",
    "        self.LoadTable()\n",
    "        self.grid(sticky = (N,S,W,E))\n",
    "        parent.grid_rowconfigure(0, weight = 1)\n",
    "        parent.grid_columnconfigure(0, weight = 1)\n",
    "        \n",
    "    def CreateTable(self):\n",
    "        tv = Treeview(self)\n",
    "        tv['columns'] = ('pointwisemutual', 'mutual', 'viewfull')\n",
    "        tv.heading(\"#0\", text='Key Phrase')\n",
    "        tv.column(\"#0\", anchor=\"w\", width=300)\n",
    "        tv.heading('pointwisemutual', text='PMI')\n",
    "        tv.column('pointwisemutual', anchor='center', width=50)\n",
    "        tv.heading('mutual', text='MI')\n",
    "        tv.column('mutual', anchor='center', width=50)\n",
    "        tv.heading('viewfull', text='See Full Thread')\n",
    "        tv.column('viewfull', anchor='center', width=100)\n",
    "        tv.grid(sticky = (N,S,W,E))\n",
    "        self.treeview = tv\n",
    "        self.grid_rowconfigure(0, weight = 1)\n",
    "        self.grid_columnconfigure(0, weight = 1)\n",
    "        \n",
    "    ###Get Table Values\n",
    "    def LoadTable(self):\n",
    "        \n",
    "        MItable = pandas.DataFrame(columns=['text','MI', 'PMI'],index=[0,1,2,3])\n",
    "        MItable.loc[0] = pandas.Series({'text':\"Awesome room service\", 'MI':1, 'PMI':0.75})\n",
    "        MItable.loc[1] = pandas.Series({'text':\"Good view\", 'MI':0.5, 'PMI':0.75})\n",
    "        MItable.loc[2] = pandas.Series({'text':\"Ok view\", 'MI':0, 'PMI':0.5})\n",
    "        MItable.loc[3] = pandas.Series({'text':\"Bad room service\", 'MI':-0.5, 'PMI':0})\n",
    "        MItable.loc[4] = pandas.Series({'text':\"Terrible prices\", 'MI':-1, 'PMI':-0.75})\n",
    "        MItable.loc[5] = pandas.Series({'text':\"Disastrous prices\", 'MI':-1, 'PMI':-1})\n",
    "        MItable\n",
    "        \n",
    "        for (i,row) in MItable.iterrows():\n",
    "            self.treeview.insert('', 'end', text=row[\"text\"], values=(row[\"MI\"],row[\"PMI\"], 'View'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Create Timeline Bar Graph\n",
    "class TimelineApp(Frame):\n",
    "\n",
    "    def __init__(self, parent):\n",
    "        Frame.__init__(self, parent)\n",
    "        self.CreateGraph()\n",
    "        self.grid(sticky = (N,S,W,E))\n",
    "        parent.grid_rowconfigure(0, weight = 1)\n",
    "        parent.grid_columnconfigure(0, weight = 1)\n",
    "        \n",
    "    def CreateGraph(self):\n",
    "        timetable = pandas.DataFrame(columns=['month','total'],index=[0,1,2])\n",
    "        timetable.loc[0] = pandas.Series({'month':\"Jan\", 'total':50})\n",
    "        timetable.loc[1] = pandas.Series({'month':\"Feb\", 'total':35})\n",
    "        timetable.loc[2] = pandas.Series({'month':\"Mar\", 'total':29})\n",
    "        timetable.loc[3] = pandas.Series({'month':\"Apr\", 'total':15})\n",
    "        timetable.loc[4] = pandas.Series({'month':\"May\", 'total':10})\n",
    "        timetable.loc[5] = pandas.Series({'month':\"Jun\", 'total':47})\n",
    "        timetable.loc[6] = pandas.Series({'month':\"Jul\", 'total':38})\n",
    "        timetable.loc[7] = pandas.Series({'month':\"Aug\", 'total':7})\n",
    "        timetable.loc[8] = pandas.Series({'month':\"Sep\", 'total':23})\n",
    "        timetable.loc[9] = pandas.Series({'month':\"Oct\", 'total':19})\n",
    "        timetable.loc[10] = pandas.Series({'month':\"Nov\", 'total':28})\n",
    "        timetable.loc[11] = pandas.Series({'month':\"Dec\", 'total':33})        \n",
    "        \n",
    "        ###month = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "                \n",
    "        c_width = 55\n",
    "        c_height = 180\n",
    "        c = Canvas(self, width=c_width, height=c_height, bg= 'gray')\n",
    "        c.pack()\n",
    "        \n",
    "        ###sizing the graph\n",
    "        ###y height = max value * y_stretch\n",
    "        y_height=timetable.total.max()\n",
    "        y_stretch = 140/y_height\n",
    "        # gap between lower canvas edge and x axis\n",
    "        y_gap = 20\n",
    "        # stretch enough to get all data items in\n",
    "        x_stretch = 15\n",
    "        x_width = 28\n",
    "        # gap between left canvas edge and y axis\n",
    "        x_gap = 20\n",
    "        \n",
    "        c.create_line(0,c_height - y_gap,550,c_height - y_gap)\n",
    "                \n",
    "        for i,row in timetable.iterrows():\n",
    "            # calculate reactangle coordinates (integers) for each bar\n",
    "            x0 = i * x_stretch + i * x_width + x_gap\n",
    "            y0 = c_height - (row[\"total\"] * y_stretch + y_gap)\n",
    "            x1 = i * x_stretch + i * x_width + x_width + x_gap\n",
    "            y1 = c_height - y_gap\n",
    "            # draw the bar\n",
    "            c.create_rectangle(x0, y0, x1, y1, fill=\"midnightblue\")\n",
    "            # put the y value above each bar\n",
    "            c.create_text(x1, y0, anchor=SE, text=row[\"total\"])\n",
    "            c.create_text(x1, c_height-2, anchor=SE, text=row[\"month\"])\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Main Application\n",
    "class App(tkinter.Tk):\n",
    "\n",
    "    ###Initialize things\n",
    "    def __init__(self, parent):\n",
    "        tkinter.Tk.__init__(self, parent)\n",
    "        self.parent = parent\n",
    "        self.initialize()\n",
    "    \n",
    "    ###Actually initialize the program\n",
    "    def initialize(self):\n",
    "    \n",
    "        ###Create the main container frames\n",
    "        firstframe = Frame(self, bg='yellowgreen', width = 1000, height=50, padx=3, pady=3)\n",
    "        secondframe = Frame(self, bg='gray', width=1000, height=100, padx=3, pady=3)\n",
    "        thirdframe = Frame(self, bg='white', width = 1000, height = 100, padx=3, pady=3)\n",
    "        fourthframe = Frame(self, bg='lavender', width = 1000, height = 100, padx=3, pady=3)\n",
    "        fifthframe = Frame(self, bg='yellowgreen', width = 1000, height = 300, padx=3, pady=3)\n",
    "        sixthframe = Frame(self, bg='gray', width = 1000, height = 300, padx=3, pady=3)\n",
    "\n",
    "        ###layout all of the main containers\n",
    "        firstframe.grid(row=0, sticky=\"ew\")\n",
    "        secondframe.grid(row=1, sticky=\"nsew\")\n",
    "        thirdframe.grid(row=3, sticky=\"ew\")\n",
    "        fourthframe.grid(row=4, sticky=\"ew\")\n",
    "        fifthframe.grid(row=5, sticky=\"ew\")\n",
    "        sixthframe.grid(row=6, sticky=\"ew\")\n",
    "        \n",
    "        ###first frame = search box\n",
    "        submit = Button(firstframe, text =\"Search\", background=\"yellowgreen\", command=self.OnButtonClick)\n",
    "        \n",
    "        ###self.entryVariable is the search item\n",
    "        self.entryVariable = tkinter.StringVar()\n",
    "        self.entry = tkinter.Entry(firstframe,textvariable=self.entryVariable)\n",
    "        self.entry.bind(\"<Return>\", self.OnPressEnter)\n",
    "        self.entryVariable.set(\"*\")\n",
    "        \n",
    "        ###top frame layout\n",
    "        submit.grid(row=0, column=1)\n",
    "        self.entry.grid(row=0, column=0, sticky='EW')\n",
    "\n",
    "        ###second frame = summary stats\n",
    "        statslabel1= Label(secondframe, text=\"Total Comments\", bg=\"gray\")\n",
    "        statslabel2= Label(secondframe, text=\"Total Subreddits\", bg=\"gray\")\n",
    "        statslabel3= Label(secondframe, text=\"Total Positive\", bg=\"gray\", fg=\"darkgreen\")\n",
    "        statslabel4= Label(secondframe, text=\"Total Neutral\", bg=\"gray\", fg=\"yellow\")\n",
    "        statslabel5= Label(secondframe, text=\"Total Negative\", bg=\"gray\", fg=\"red\")\n",
    "        \n",
    "        self.statResult1 = tkinter.StringVar()\n",
    "        self.statResult2 = tkinter.StringVar()        \n",
    "        self.statResult3 = tkinter.StringVar()        \n",
    "        self.statResult4 = tkinter.StringVar()        \n",
    "        self.statResult5 = tkinter.StringVar()\n",
    "        \n",
    "        self.statResult1.set(u\"0\")\n",
    "        self.statResult2.set(u\"0\")\n",
    "        self.statResult3.set(u\"0\")\n",
    "        self.statResult4.set(u\"0\")\n",
    "        self.statResult5.set(u\"0\")\n",
    "        \n",
    "        resultlabel1 = Label(secondframe,textvariable=self.statResult1, bg=\"gray\")\n",
    "        resultlabel2 = Label(secondframe,textvariable=self.statResult2, bg=\"gray\")\n",
    "        resultlabel3 = Label(secondframe,textvariable=self.statResult3, bg=\"gray\")\n",
    "        resultlabel4 = Label(secondframe,textvariable=self.statResult4, bg=\"gray\")\n",
    "        resultlabel5 = Label(secondframe,textvariable=self.statResult5, bg=\"gray\")\n",
    "\n",
    "        ###second frame layout\n",
    "        statslabel1.grid(row=0, column=0)\n",
    "        statslabel2.grid(row=0, column=2)\n",
    "        statslabel3.grid(row=1, column=0, sticky=\"w\")\n",
    "        statslabel4.grid(row=1, column=2)\n",
    "        statslabel5.grid(row=1, column=4)\n",
    "\n",
    "        resultlabel1.grid(row=0, column=1)\n",
    "        resultlabel2.grid(row=0, column=3)\n",
    "        resultlabel3.grid(row=1, column=1)\n",
    "        resultlabel4.grid(row=1, column=3)\n",
    "        resultlabel5.grid(row=1, column=5)\n",
    "\n",
    "        ###third frame = Key Phrase with PMI and MI headers\n",
    "        keyphraselabel = Label(thirdframe, text=\"Key Phrases for\")\n",
    "        keyphrasesearch = Label(thirdframe, textvariable=self.entryVariable)\n",
    "        keyphraseshow = Label(thirdframe, text=\"Show: \")\n",
    "        \n",
    "        choice = StringVar()\n",
    "        choice.set(\"all\")\n",
    "        self.RB1 = Radiobutton(thirdframe, text=\"all\", variable=choice, value=\"all\", state=\"disabled\")\n",
    "        self.RB2 = Radiobutton(thirdframe, text=\"pos\", variable=choice, value=\"pos\", state=\"disabled\")\n",
    "        self.RB3 = Radiobutton(thirdframe, text=\"neg\", variable=choice, value=\"neg\", state=\"disabled\")\n",
    "        \n",
    "        showallcomments = Button(thirdframe, text =\"Show All Comments\", command=self.SecondWindow)\n",
    "                \n",
    "        ###third frame layout\n",
    "        keyphraselabel.grid(row=0,column=0)\n",
    "        keyphrasesearch.grid(row=0,column=1)\n",
    "        keyphraseshow.grid(row=0,column=3)\n",
    "        self.RB1.grid(row=0, column=4)\n",
    "        self.RB2.grid(row=0, column=5)\n",
    "        self.RB3.grid(row=0, column=6)\n",
    "        showallcomments.grid(row=0, column=7)\n",
    "        \n",
    "        ###fourthframe = Table\n",
    "        TableApp(fourthframe)\n",
    "        \n",
    "        ###fifth frame = Timeline Header\n",
    "        timelinehead = Label(fifthframe, text=\"Comment Frequency Timeline\", bg=\"yellowgreen\")\n",
    "        \n",
    "        timelinehead.grid(row=0, column=0)\n",
    "        \n",
    "        ###sixth frame = Actual Timeline\n",
    "        TimelineApp(sixthframe)\n",
    "        \n",
    "    ###Click Submit Button and show all search\n",
    "    def OnButtonClick(self):\n",
    "        print(\"OnButtonClick\")\n",
    "        searchTable = shopifySearch(df,self.entryVariable.get())\n",
    "        print(searchTable)\n",
    "        self.RB1.configure(state=\"normal\")\n",
    "        self.RB2.configure(state=\"normal\")\n",
    "        self.RB3.configure(state=\"normal\")\n",
    "        self.RB1.select()\n",
    "        #invoke search function\n",
    "        \n",
    "    ###search function to be implemented\n",
    "        \n",
    "    ###summary statistics\n",
    "\n",
    "    ###Click Enter and show all search\n",
    "    def OnPressEnter(self,event):\n",
    "        print(\"OnPressEnter\")\n",
    "        self.RB1.configure(state=\"normal\")\n",
    "        self.RB2.configure(state=\"normal\")\n",
    "        self.RB3.configure(state=\"normal\")\n",
    "        self.RB1.select()\n",
    "        # invoke\n",
    "        \n",
    "    ###Create Second Window    \n",
    "    def SecondWindow(self):\n",
    "        \n",
    "        child = tkinter.Toplevel(self)\n",
    "        child.title(\"Comments\")\n",
    "        ###Create the main container frames\n",
    "        windowfirst = Frame(child, bg='yellowgreen', width = 1000, height=50, padx=3, pady=3)\n",
    "        windowsecond = Frame(child, bg='gray', width=1000, height=100, padx=3, pady=3)\n",
    "\n",
    "        ###layout all of the main containers\n",
    "        windowfirst.pack()\n",
    "        windowsecond.pack()\n",
    "\n",
    "        ##comment \n",
    "        ctr_left = Frame(windowsecond, bg='red', width=500, height=300, padx=3, pady=3)\n",
    "        ctr_right = Frame(windowsecond, bg='brown', width=500, height=300, padx=3, pady=3)\n",
    "\n",
    "        ctr_left.grid(row=0, column = 0, sticky=\"ns\")\n",
    "        ctr_right.grid(row=0, column = 2, sticky=\"ns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "OnButtonClick\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vibhorsachdeva/anaconda/lib/python3.5/site-packages/pandas/indexes/base.py\", line 1986, in get_value\n",
      "    return tslib.get_value_box(s, key)\n",
      "  File \"pandas/tslib.pyx\", line 777, in pandas.tslib.get_value_box (pandas/tslib.c:17017)\n",
      "  File \"pandas/tslib.pyx\", line 786, in pandas.tslib.get_value_box (pandas/tslib.c:16691)\n",
      "TypeError: 'str' object cannot be interpreted as an integer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vibhorsachdeva/anaconda/lib/python3.5/tkinter/__init__.py\", line 1550, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"<ipython-input-23-32781f7a02f8>\", line 116, in OnButtonClick\n",
      "    searchTable = shopifySearch(df,self.entryVariable.get())\n",
      "  File \"<ipython-input-18-298bb3ef7204>\", line 62, in shopifySearch\n",
      "    writer.add_document(comment_ID = data['name'],\n",
      "  File \"/Users/vibhorsachdeva/anaconda/lib/python3.5/site-packages/pandas/core/series.py\", line 583, in __getitem__\n",
      "    result = self.index.get_value(self, key)\n",
      "  File \"/Users/vibhorsachdeva/anaconda/lib/python3.5/site-packages/pandas/indexes/base.py\", line 1994, in get_value\n",
      "    raise e1\n",
      "  File \"/Users/vibhorsachdeva/anaconda/lib/python3.5/site-packages/pandas/indexes/base.py\", line 1980, in get_value\n",
      "    tz=getattr(series.dtype, 'tz', None))\n",
      "  File \"pandas/index.pyx\", line 103, in pandas.index.IndexEngine.get_value (pandas/index.c:3332)\n",
      "  File \"pandas/index.pyx\", line 111, in pandas.index.IndexEngine.get_value (pandas/index.c:3035)\n",
      "  File \"pandas/index.pyx\", line 159, in pandas.index.IndexEngine.get_loc (pandas/index.c:4018)\n",
      "  File \"pandas/hashtable.pyx\", line 675, in pandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12368)\n",
      "  File \"pandas/hashtable.pyx\", line 683, in pandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12322)\n",
      "KeyError: 'name'\n"
     ]
    }
   ],
   "source": [
    "root = App(None)\n",
    "root.title('Shopify Reddit Analyzer')\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
